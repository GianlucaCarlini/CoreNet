{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from .segmentation_models.core.models import Unet\n",
    "import cv2\n",
    "from .segmentation_models.core.utils import predict_big_image\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyMeanIOU(tf.keras.metrics.MeanIoU):\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        return super().update_state(y_true, tf.argmax(y_pred, axis=-1), sample_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Augment(tf.keras.layers.Layer):\n",
    "  def __init__(self, seed=42):\n",
    "    super().__init__()\n",
    "    # both use the same seed, so they'll make the same random changes.\n",
    "    self.flip_inputs_h = tf.keras.layers.RandomFlip(mode=\"horizontal\", seed=seed)\n",
    "    self.flip_inputs_w = tf.keras.layers.RandomFlip(mode=\"vertical\", seed=seed)\n",
    "    self.flip_labels_h = tf.keras.layers.RandomFlip(mode=\"horizontal\", seed=seed)\n",
    "    self.flip_labels_w = tf.keras.layers.RandomFlip(mode=\"vertical\", seed=seed)\n",
    "    \n",
    "    self.rotate_inputs = tf.keras.layers.RandomRotation(factor=1., fill_mode='constant', seed=seed)\n",
    "    self.rotate_labels = tf.keras.layers.RandomRotation(factor=1., fill_mode='constant', seed=seed)\n",
    "\n",
    "    self.rnd_contrast = tf.keras.layers.RandomContrast(factor=0.05, seed=seed)\n",
    "    self.rnd_bright = tf.keras.layers.RandomBrightness(factor=0.05, seed=seed)\n",
    "\n",
    "  def call(self, inputs, labels):\n",
    "\n",
    "    inputs = self.rotate_inputs(inputs)\n",
    "    labels = self.rotate_labels(labels)\n",
    "    inputs = self.rnd_contrast(inputs)\n",
    "    inputs = self.rnd_bright(inputs)\n",
    "\n",
    "    return inputs, labels\n",
    "\n",
    "imdir_train = \"./Training/Patch/Images/\"\n",
    "mdir_train = \"./Training/Patch/Annotations/\"\n",
    "\n",
    "imdir_val = \"./Validazione/Patch/Images/\"\n",
    "mdir_val = \"./Validazione/Patch/Annotations/\"\n",
    "\n",
    "\n",
    "train_imgs = tf.keras.utils.image_dataset_from_directory(\n",
    "    imdir_train,\n",
    "    labels=None,\n",
    "    batch_size=8,\n",
    "    image_size=(384, 384),\n",
    "    color_mode=\"rgb\",\n",
    "    seed=42,\n",
    ")\n",
    "train_masks = tf.keras.utils.image_dataset_from_directory(\n",
    "    mdir_train,\n",
    "    labels=None,\n",
    "    batch_size=8,\n",
    "    image_size=(384, 384),\n",
    "    color_mode=\"grayscale\",\n",
    "    seed=42,\n",
    ")\n",
    "val_imgs = tf.keras.utils.image_dataset_from_directory(\n",
    "    imdir_val,\n",
    "    labels=None,\n",
    "    batch_size=8,\n",
    "    image_size=(384, 384),\n",
    "    color_mode=\"rgb\",\n",
    "    seed=42,\n",
    ")\n",
    "val_masks = tf.keras.utils.image_dataset_from_directory(\n",
    "    mdir_val,\n",
    "    labels=None,\n",
    "    batch_size=8,\n",
    "    image_size=(384, 384),\n",
    "    color_mode=\"grayscale\",\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "train_ds = tf.data.Dataset.zip((train_imgs, train_masks))\n",
    "val_ds = tf.data.Dataset.zip((val_imgs, val_masks))\n",
    "\n",
    "train_ds = train_ds.map(Augment())\n",
    "\n",
    "train_ds = train_ds.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "val_ds = val_ds.prefetch(buffer_size=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LUT = np.zeros(shape=(7,3), dtype=np.uint8)\n",
    "\n",
    "LUT[0] = [0, 0, 0]          # Background\n",
    "LUT[1] = [244, 229, 136]    # WDF\n",
    "LUT[2] = [104, 180, 46]     # Swamp\n",
    "LUT[3] = [42, 75, 155]      # Organic\n",
    "LUT[4] = [241, 137, 24]     # Sand\n",
    "LUT[5] = [128, 192, 123]    # PDF\n",
    "LUT[6] = [106, 69, 149]     # ProDelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img, mask in train_ds.take(1):\n",
    "\n",
    "    for i in range(8):\n",
    "        fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(10, 10))\n",
    "        ax1.imshow(img[i].numpy().astype(np.uint8))\n",
    "        ax2.imshow(LUT[mask[i].numpy().astype('uint8')[..., 0]])\n",
    "        ax1.imshow(LUT[mask[i].numpy().astype('uint8')[..., 0]], alpha=0.2)\n",
    "        ax1.axis('off') ; ax2.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 100\n",
    "starter_learning_rate = 1e-4\n",
    "end_learning_rate = 5e-6\n",
    "decay_steps = train_ds.cardinality().numpy() * EPOCHS\n",
    "learning_rate_fn = tf.keras.optimizers.schedules.PolynomialDecay(\n",
    "    starter_learning_rate,\n",
    "    decay_steps,\n",
    "    end_learning_rate,\n",
    "    power=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath='best_model.h5',\n",
    "    save_weights_only=True,\n",
    "    monitor='val_my_mean_iou',\n",
    "    mode='max',\n",
    "    save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Unet((384, 384, 3), backbone=\"efficientnetb3\", classes=7, final_activation='softmax')\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(\n",
    "        learning_rate=learning_rate_fn,\n",
    "        name=\"Adam\",\n",
    "        \n",
    "    ),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "    metrics=[MyMeanIOU(num_classes=7)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_ds, epochs=EPOCHS, validation_data=val_ds, callbacks=[model_checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = pd.DataFrame.from_dict(history.history)\n",
    "hist.to_csv('history_effnetb3.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f08154012ddadd8e950e6e9e035c7a7b32c136e7647e9b7c77e02eb723a8bedb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
