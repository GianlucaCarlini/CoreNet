{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantization(img, palette):\n",
    "\n",
    "    distance = np.linalg.norm(img[:, :, None] - palette[None, None, :], axis=3)\n",
    "\n",
    "    quantized = np.argmin(distance, axis=2).astype(\"uint8\")\n",
    "\n",
    "    return quantized\n",
    "\n",
    "\n",
    "palette = np.array(\n",
    "    [\n",
    "        [29, 29, 27],       # Background\n",
    "        [244, 229, 136],    # WDF\n",
    "        [104, 180, 46],     # Swamp\n",
    "        [42, 75, 155],      # Organic\n",
    "        [241, 137, 24],     # Sand\n",
    "        [128, 192, 123],    # PDF\n",
    "        [106, 69, 149]      # ProDelta\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_patches(img, patch_size, mask, savedirs, stride=None, thresh=0.1):\n",
    "    \"\"\"Generates pathces of a given size from an image and saves them to disk\n",
    "\n",
    "    Args:\n",
    "        img (np.array): The image to be patched\n",
    "        patch_size (int): The size of the patch\n",
    "        mask (np.array): The segmentation mask associated with the image.\n",
    "        savedirs (list): A list of two paths were image and mask patches are saved.\n",
    "        stride (int, optional): The size of the stride to generate patches. Defaults to None.\n",
    "        thresh (float, optional): The threshold to exclude patches that are mostly background.\n",
    "            The patch is saved if the number of foreground pixels is higher then thres in percentage.\n",
    "            Defaults to 0.1.\n",
    "    \"\"\"\n",
    "\n",
    "    if stride is None:\n",
    "        stride = patch_size\n",
    "\n",
    "    h, w, _ = img.shape\n",
    "\n",
    "    n_patch_h = ((h - patch_size) // stride) + 1\n",
    "    n_patch_w = ((w - patch_size) // stride) + 1\n",
    "\n",
    "    n_patch = n_patch_w * n_patch_h\n",
    "\n",
    "    y = np.arange(n_patch_h)\n",
    "    x = np.arange(n_patch_w)\n",
    "    xy = np.meshgrid(x, y)\n",
    "\n",
    "    x = xy[0].ravel() * stride\n",
    "    y = xy[1].ravel() * stride\n",
    "    x2 = x + patch_size\n",
    "    y2 = y + patch_size\n",
    "\n",
    "    for i in range(n_patch):\n",
    "\n",
    "        patch_img = img[y[i] : y2[i], x[i] : x2[i]].astype(np.uint8)\n",
    "        patch_mask = mask[y[i] : y2[i], x[i] : x2[i]].astype(np.uint8)\n",
    "\n",
    "        if np.count_nonzero(patch_mask) > thresh * patch_size**2:\n",
    "            cv2.imwrite(f\"{savedirs[0]}_{i}.png\", patch_img)\n",
    "            cv2.imwrite(f\"{savedirs[1]}_{i}.png\", patch_mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdir = \"../Sondaggi/Immagini_ALL/\"\n",
    "maskdir = \"../Sondaggi/Annotazioni_ALL/\"\n",
    "\n",
    "saveimdir = \"../Sondaggi/Immagini_ALL_patch/\"\n",
    "savemaskdir = \"../Sondaggi/Annotazioni_ALL_patch/\"\n",
    "\n",
    "imgs = os.listdir(imdir)\n",
    "masks = os.listdir(maskdir)\n",
    "\n",
    "target_h = 1538\n",
    "target_w = 3074\n",
    "\n",
    "for im, msk in zip(imgs, masks):\n",
    "\n",
    "    img = cv2.imread(os.path.join(imdir, im))\n",
    "    mask = cv2.imread(os.path.join(maskdir, msk))\n",
    "    mask = cv2.cvtColor(mask, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    h, w, _ = img.shape\n",
    "\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    mask = np.expand_dims(mask, axis=0)\n",
    "\n",
    "    method = \"bilinear\" if h < target_h else \"area\"\n",
    "\n",
    "    img = tf.image.resize_with_pad(\n",
    "        img,\n",
    "        target_height=target_h,\n",
    "        target_width=target_w,\n",
    "        method=method,\n",
    "        antialias=True,\n",
    "    )\n",
    "    mask = tf.image.resize_with_pad(\n",
    "        mask, target_height=target_h, target_width=target_w, method=\"nearest\"\n",
    "    )\n",
    "\n",
    "    img = img.numpy().squeeze()\n",
    "    mask = mask.numpy().squeeze()\n",
    "\n",
    "    img = img[1:-1, 1:-1]\n",
    "    mask = mask[1:-1, 1:-1]\n",
    "\n",
    "    quant = quantization(mask, palette)\n",
    "\n",
    "    save_patches(\n",
    "        img,\n",
    "        patch_size=384,\n",
    "        mask=quant,\n",
    "        stride=384,\n",
    "        pad=False,\n",
    "        thresh=0.1,\n",
    "        savedirs=[\n",
    "            os.path.join(saveimdir, im[:-4]),\n",
    "            os.path.join(savemaskdir, msk[:-4]),\n",
    "        ],\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f08154012ddadd8e950e6e9e035c7a7b32c136e7647e9b7c77e02eb723a8bedb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
